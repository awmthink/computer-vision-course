# Hugging Face 的努力：伦理与社会 🤗🌎

希望你喜欢探索计算机视觉中有关伦理和偏见的单元。在我们结束本单元时，让我们来看看 Hugging Face 为改善社会伦理所做的努力。本章将鼓励你探索 AI 中的伦理和偏见，这一领域不断发展。Hugging Face 的核心使命是*民主化优质的机器学习*。那么什么是优质机器学习（Good ML）？有一些原则用于定义优质机器学习。

## 民主化优质机器学习 🤗

**1. 协作：** 提供工具以便与开源社区更好地协作。这些工具的一些示例包括：
   - [*模型卡*](https://huggingface.co/docs/hub/model-cards)：这是伴随模型的文件，提供有关模型、其预期用途和潜在限制（包括伦理考量）、训练参数和实验信息、训练数据集和评估结果的详细信息。这确保了上传到平台的模型对社区透明开放。
   - [*评估工具*](https://huggingface.co/blog/eval-on-the-hub)：允许用户无需编写代码就可以在 Hub 上公开的数据集上评估任何模型。
   - [*社区讨论*](https://huggingface.co/blog/community-update)：无论你是上传模型、数据集或空间，还是只是想更多了解作者的相关内容，大家都可以提供反馈、标记特定空间、通过 PR 直接改进或贡献到库中。
   - [*Discord 社群*](https://discord.com/invite/JfAtkvEtRb)：🤗 社群中有许多频道讨论不同的领域，如强化学习、NLP、游戏开发、音频处理、计算机视觉等。

**2. 透明性：** 公开数据来源、模型训练和性能的意图。此方面的努力包括：
   - [*多模态项目伦理章程*](https://huggingface.co/blog/ethical-charter-multimodal)：讨论了 🤗 多模态学习小组的价值观，这是一个特定项目的章程。
   - [*AI 政策工作*](https://huggingface.co/blog/us-national-ai-research-resource)：提到 Hugging Face 对美国国家 AI 研究资源中期报告的回应。

**3. 责任：** 评估机器学习模型和工具的影响，使其更加可审计和易于理解，即使对不太精通机器学习的人也是如此。相关努力包括：
   - [🤗 *教育项目*](https://huggingface.co/blog/education)：旨在向各种背景的人进行教育，包括初学者和教师。多位专家和团队成员组织聚会、会议和研讨会。
   - [*数据测量工具*](https://huggingface.co/spaces/huggingface/data-measurements-tool)：这是一个交互界面和开源库，允许数据集创建者和用户自动计算对负责任的数据开发有意义和实用的指标。

## Hugging Face 空间的分类

接下来，让我们看看 Hugging Face 如何对空间进行分类。根据机器学习中的伦理考量，Hugging Face 将空间分为以下六个高级类别：

### ✍️ 严谨性

严谨性项目特别关注检测失败案例，通过安全措施保护隐私，并确保潜在用户（无论技术性强或弱）了解项目的局限性。一些示例：
- 使用有充分文档支持的模型卡构建的项目。
- 提供模型训练过程和行为透明度的工具。
- 基于前沿基准进行评估，并在分解数据集上报告结果。
- 展示模型在性别、肤色、种族、年龄或其他属性方面的失败案例。
- 减少过拟合和训练数据记忆化等问题的技术。
- 去毒化语言模型的技术。

一个示例空间是 [**扩散偏差探索器**](https://huggingface.co/spaces/society-ethics/DiffusionBiasExplorer)，该工具允许用户比较三个文本到图像模型（SD 1.4、SD 2.0 和 Dall-E 2）在不同提示词下对不同职业和形容词的表现。

### 🤝 共识

共识技术支持使用和受这些技术影响的人们的自我决策。一些示例：
- 展示从知情、自愿并获得合理报酬的来源获取数据的承诺。
- 设计尊重终端用户自主权的系统，例如隐私保护技术。
- 避免剥削性、沙文主义、“黑暗”以及其他“不道德”的互动模式。

此类别的一些示例空间包括：
1. [**CLIP 识别我的脸吗**](https://huggingface.co/spaces/AIML-TUDA/does-clip-know-my-face)：该空间允许你选择模型、输入名字并上传照片。根据这些信息，模型会尝试从图像中预测你的名字，如果多张图像正确预测你的名字，说明你可能曾在训练数据中。
2. [**Photoguard**](https://huggingface.co/spaces/RamAnanth1/photoguard)：该空间展示了一种保护图像免受 ML 驱动的照片编辑模型（如 SD）操控的方式，通过图像免疫化来实现保护。

### 👁️‍🗨️ 社会意识

社会意识工作展示了机器学习如何支持构建更强大的社会。一些示例：
- 使用机器学习帮助应对气候变化。
- 构建协助医学研究和实践的工具。
- 用于文本转语音、图像描述等任务的模型，旨在提高无障碍性。
- 创建数字人文学科的系统，如复兴土著语言。

一些示例空间：
1. [**苏格拉底模型图像描述**](https://huggingface.co/spaces/Geonmo/socratic-models-image-captioning-with-BLOOM)
2. [**图像描述模型对比**](https://huggingface.co/spaces/nielsr/comparing-captioning-models)

### 🌎 可持续性

这一类别的工作强调和探索使机器学习在生态上更加可持续的技术。一些示例：
- 跟踪训练大型语言模型和运行推理的碳排放。
- 量化和蒸馏方法，在不牺牲模型质量的前提下减少碳足迹。

一些示例空间包括：
1. [**EfficientFormer**](https://huggingface.co/spaces/adirik/efficientformer)
2. [**EfficientNetV2 深度伪造视频检测器**](https://huggingface.co/spaces/Ron0420/EfficientNetV2_Deepfakes_Video_Detector)

### 🧑‍🤝‍🧑 包容性

这些项目旨在扩大构建机器学习系统和受益者的范围。一些示例：
- 策划多样化的数据集，以增加服务不足群体的代表性。
- 使用 Hugging Face Hub 上尚未提供的语言训练语言模型。
- 创建允许非技术人员参与 AI 的无代码和低代码框架。

一个示例空间是 [**Promptist 演示**](https://huggingface.co/spaces/microsoft/Promptist)。

### 🤔 探究性

一些项目采取激进的新方法来探讨可能已司空见惯的概念。这些项目通常根植于批判理论，揭示不平等和权力结构，促使社区重新思考其与技术的关系。一些示例：
- 从土著视角重新定义 AI 和机器学习。
- 强调 LGBTQIA2S+ 群体在 AI 中的边缘化问题。
- 批判 AI 系统带来的伤害。
- 探讨“开放性”在 AI 研究中的作用。

一个示例空间是 [**PAIR：数据集的世界观**](https://huggingface.co/spaces/merve/dataset-worldviews)。

最后，如果你想进一步了解 Hugging Face 的努力，请查看 Hugging Face 上的 [**社会与伦理**](https://huggingface.co/society-ethics) 组织。也可以查看 [**#ethics-and-society**](https://discord.gg/hugging-face-879548962464493619) Discord 频道中的专用频道。