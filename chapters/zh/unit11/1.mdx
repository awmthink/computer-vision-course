# 引言

<Tip>
除了基础知识外，本单元假设您已熟悉迁移学习和多模态学习的概念。如果您未按课程顺序观看，我们建议至少阅读第2单元的迁移学习部分，以及完整的第4单元。
</Tip>

## 关于泛化

现在我们已经训练了模型，就像一个学生在考试前紧张复习所有的时代一样，真正的考验开始了！我们希望模型在训练中获取的知识不仅限于特定的图像（例如猫的图片），而是能够识别未见过的猫，比如Alice和Ted的毛茸茸的朋友。可以把它想象成模型学会了猫的“本质”，而不仅仅是那些在训练中看到的具体猫脸。这种将知识应用到新情境的能力称为**泛化**，这也是一个优秀的猫模型与一个简单的猫图片记忆器的区别。您能想象一个没有泛化的平行宇宙吗？其实很简单，只要训练模型在世界上所有的猫的图片上（假设它们只存在于地球上），包括Alice和Ted的猫，然后想办法阻止当前的猫种群繁殖。所以，是的，没什么大不了的。

实际上，当我们说模型能够泛化到所有未见过的猫图片时，并不是完全准确的。它被期望能泛化到与其训练数据分布相同的猫图片。简单来说，如果您的模型在猫自拍照上进行训练，然后向它展示一张卡通猫的图片，它可能无法识别。这两张图片来自完全不同的分布或领域。让您的猫自拍模型能够识别卡通猫称为**领域适应**（我们稍后会简单介绍）。这就像把模型在真实猫身上学到的知识应用于识别动画猫的“表亲”。

所以，我们已经从泛化，识别未见的Alice和Ted的猫图片，延伸到了领域适应，识别动画猫图片。但我们的要求更高。您不希望模型只能够识别您或Alice和Ted的猫图片，甚至不仅限于卡通猫！训练了一个猫图片的模型后，您还希望它能够识别羊驼和猎鹰的图片。

好了，现在我们进入了零样本学习（也称为ZSL）的领域。

[comment]: # (TODO: 插图展示泛化、领域适应和ZSL的区别)

## 什么是零样本学习？

让我们先定义一下。零样本学习是一种设置，在测试时模型仅被展示它在训练中**未接触过**的类别的图像。换句话说，训练集和测试集是**不相交**的。
提醒一下：在经典的ZSL设置中，测试集中只包含模型以前没见过的类别的图片，完全没有它在训练中见过的。这可能看起来有点不现实，有点像让一个学生在没有学习过相关材料的情况下参加考试。
幸运的是，有一种更实用的ZSL版本，它没有这么严格的规则，称为广义零样本学习（GZSL）。这种更灵活的方法允许测试集中包含已见和未见的类别。这更贴近现实世界的工作方式。

[comment]: # (TODO: 插图展示ZSL和GZSL的区别)

## 零样本学习的历史

在深度学习开始变得可行之后不久，关于是否可以让模型在未明确训练的任务上表现良好的问题便被提出了。2008年，在人工智能促进协会（AAAI）会议上，两个独立的论文种下了ZSL的种子。第一篇论文，题为**无数据分类**，探讨了在自然语言处理（NLP）中的零样本学习概念。第二篇，题为**零数据学习**，则聚焦于将ZSL应用于计算机视觉任务。零样本学习这个术语首次出现在2009年的NeurIPS会议上的一篇由Geoffrey Hinton等人共同撰写的论文中。

以下是ZSL历史上最重要的时刻概要。

|      |                                                                         |
|------|-------------------------------------------------------------------------|
| 2008 | ZSL概念的首次提出                                                       |
| 2009 | “零样本学习”术语的提出                                                 |
| 2013 | 广义零样本学习的概念被引入                                              |
| 2017 | 首次将编码器-解码器范式应用于ZSL                                         |
| 2020 | OpenAI的GPT-3在零样本NLP上取得显著表现                                   |
| 2021 | OpenAI的CLIP将零样本计算机视觉推向了新的高度                              |

CLIP的影响深远，开启了零样本计算机视觉研究的新纪元。其多功能性和出色的性能带来了令人振奋的新可能性。可以说，零样本计算机视觉的历史可以划分为两个时代：**CLIP之前**和**CLIP之后**。

## 零样本学习在计算机视觉中的工作原理

既然我们了解了零样本学习的概念，接下来了解它在计算机视觉中的应用会更有意义。本部分将在后续章节中详细讲解，但我们在这里先勾勒一个大概的画面，作为开篇。

在NLP中，零样本学习（尽管并非一开始如此）相对简单。许多语言模型通过在大量文本数据上进行训练，学习预测给定序列中的下一个词。这种捕捉语言内在模式和语义关系的能力使这些模型在未明确训练的任务上表现得相当出色。一个很好的例子是GPT-2在提示后附加“TL;DR”时能够总结文章。然而，零样本计算机视觉则是另一回事。

先回答一个简单的问题，*人类是如何做到的？我们是如何识别之前未见过的物体的？

对了，答案就是我们需要关于那个物体的**其他信息**。例如，给我们看一只老虎，即使我们没见过，我们也可以通过对狮子的了解来识别：一只老虎是有条纹且没有鬃毛的狮子。斑马是一种黑白条纹的马。而死侍是穿着红黑装的蜘蛛侠。

正是因为这种其他信息，零样本计算机视觉本质上是多模态的。如果说泛化是通过读书和交流来学习一种语言，那么零样本计算机视觉就是通过阅读词典并听取他人描述其发音来学习语言。

<Tip>
我们能将零样本学习视为无监督学习问题吗？不，这仍然是监督学习。在无监督学习中，模型从未标记的数据中学习。在零样本学习中，模型从没有数据的标签中学习，记得它在早期被称为无数据分类。
</Tip>

### 什么是其他信息？

为了让零样本计算机视觉工作，我们需要在训练期间向模型提供除视觉特征以外的信息。这些其他信息称为**语义或辅助信息**。它在视觉特征和未见类别之间提供了语义桥梁。通过融合这种多模态信息（文本和图像），零样本计算机视觉模型可以在从未见过的视觉上识别对象。换句话说，语义信息在高维向量中嵌入了**已见和未见类别**，其形式多种多样：

1. **属性向量**：将属性视为对象不同特征的表格表示。
2. **文本描述**：类似于图像标题的描述图片中对象的文本。
3. **类别标签向量**：这些是类别标签本身的嵌入。

[comment]: # (TODO: 插图展示不同形式的语义信息)

利用这些语义信息，您训练模型学习图像特征和语义特征之间的映射函数。在推理时，模型通过在语义空间中寻找最接近的标签来预测类别，例如使用k近邻算法。可以说，我们是利用语义信息从已见类别中转移了知识。

不同的零样本计算机视觉方法在它们所使用的**语义信息**以及推理时所利用的**嵌入空间**方面各不相同。

[comment]: # (TODO: 插图展示零样本学习的流程)

### 这与迁移学习有何不同？

好问题！零样本学习（ZSL）属于迁移学习的更广泛范畴，尤其是在**异质迁移学习**之下。这意味着ZSL依赖于从**源领域**（已见类别）向**不同目标领域**（未见类别）传递知识。

由于源领域和目标领域之间的差异，ZSL在迁移学习中面临一些特定的挑战。这些挑战包括克服数据分布显著不同的领域偏移以及在目标领域缺乏标记数据等问题。但我们会在后面详细讨论这些挑战，所以现在无需担心。现在，让我们来简单了解一些不同的零样本计算机视觉方法。

## 零样本计算

机视觉的方法

零样本计算机视觉方法的种类繁多，提出了众多方法，并有多种分类框架。但我认为有一种分类框架很有吸引力，即将这些方法大致分为**基于嵌入的方法**和**基于生成的方法**。这个框架提供了一个理解和比较不同零样本计算机视觉方法的有用视角。

- **基于嵌入的方法**：模型学习一个通用的嵌入空间，在该空间中投影图像和它们的语义特征/表示。新出现的未见类别可以通过该空间中的相似性度量进行预测。例如，CLIP。
- **基于生成的方法**：这些方法利用生成模型基于已见类别的样本和已见及未见类别的语义表示生成未见类别的合成图像或视觉特征。这使得能够在没有真实数据的情况下在这些未见类别上训练模型。这样，我们在一定程度上将零样本问题转换成了监督学习问题。例如，CVAE[^6]。

[comment]: # (TODO: 图解展示ZSL方法的分类和子分类)

在嵌入法和生成法之间的选择，就像机器学习中您必须做的其他选择一样，*取决于*任务的具体情况和可用资源。嵌入方法通常因其效率和可扩展性而被优先选择，而生成方法则在处理复杂数据方面具有更大的灵活性和潜力。

但无论如何，在本单元中我们将只讲解基于嵌入的方法，包括**基于注意力的嵌入方法**。零样本学习是一个很大的主题，全面覆盖可能需要单独的课程。有兴趣的读者可以查阅提供的额外阅读资料并享受其中的乐趣。

## 克隆入侵：ZSL与其他方法的区别？

我们已经走了很长的路！现在我们对零样本学习、其历史、在计算机视觉中的应用及其工作方式有了基本的了解。为了完整本介绍，我们将比较ZSL与其他可能看似相似的方法的区别。

- **领域适应（DA）**：这应该很熟悉了。我们可以将零样本学习视为领域适应的一个极端案例（贪婪，贪婪），处理在完全没有数据的情况下学习识别未见类别的问题。领域适应聚焦于弥合两个分布不同但相关的领域（数据集）之间的差距，并且需要标记数据。
- **开放集识别（OSR）**：可以把它看作是一个布尔型的零样本学习。在OSR问题中，模型同时处理已见和未见类别。但与ZSL不同的是，模型在测试时只需分类实例是否属于已见类别。这就是全部了，没有什么复杂的标签。然而，这仍然是一个显著的挑战。
- **分布外（OOD）检测**：这个问题可以看作是开放集识别的连续变体。在这里，我们并不想检测所有未包含在训练过程中的实例，而是仅仅检测显著偏离训练数据分布的实例。通过有效地识别和处理意外数据，OOD检测可以为更可信和稳健的AI系统铺平道路，使其能够适应不可预测的环境。
- **开放词汇学习（OVL）**：这是零样本学习的目标。就像“ZSL的增强版”。总的来说，OVL可以被认为是ZSL的扩展，包含了在处理未见类别的同时从有限数据中学习的能力，同时还能扩展以处理已见类别以及潜在的无限新类别和任务。

## 参考文献

- [A fast learning algorithm for deep belief nets](https://dl.acm.org/doi/10.1162/neco.2006.18.7.1527)
- [Zero-Shot Learning Through Cross-Modal Transfer](https://arxiv.org/abs/1301.3666)
- [Semantic Autoencoder for Zero-Shot Learning](https://arxiv.org/abs/1704.08345)
- [Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165)
- [Learning Transferable Visual Models From Natural Language Supervision](https://arxiv.org/abs/2103.00020)
- [Learning Structured Output Representation using Deep Conditional Generative Models](https://papers.nips.cc/paper_files/paper/2015/hash/8d55a249e6baa5c06772297520da2051-Abstract.html)