# 隐私、偏见和社会关注

AI驱动的图像编辑工具的广泛应用引发了隐私、偏见和潜在的社会影响的重大关注。这些工具能够以惊人的逼真度操控2D和3D图像，带来了伦理困境，亟需审慎考虑。

本章您将学习以下内容：

- 此类AI图像/视频对社会的影响
- 当前应对这些问题的方法
- 未来的发展方向

## 对社会的影响

轻松编辑和修改图像的能力可能会导致：

- **削弱对媒体的信任**：深度伪造技术（Deepfakes）能够通过逼真的伪造视频传播虚假信息，从而削弱公众对新闻和在线内容的信任。
- **骚扰和诽谤个人**：恶意行为者可以利用AI工具创建虚假图像进行骚扰、诽谤等有害行为。
- **创造不现实的美丽标准**：AI工具可以被用来编辑图像以符合不现实的美丽标准，负面影响自尊和身体形象。

## 当前的应对方法

目前正在使用几种方法来解决这些问题：

- **透明性和标识**：鼓励平台和开发者对AI编辑的图像的使用保持透明，并实施标识系统以区分真实内容和被操控的内容。
- **事实核查和验证**：媒体和科技公司正在投资于事实核查和验证工具，以帮助打击错误信息和虚假信息的传播。
- **法律框架**：政府正在考虑立法措施，以规范AI编辑图像的使用，并对滥用行为者追责。

## 未来的发展方向

AI编辑图像的未来可能涉及：

- **高级检测和缓解技术**：研究人员理想地会开发出更先进的技术，用于检测和缓解与AI编辑图像相关的危害。但这像是一场猫鼠游戏，一方开发出复杂的逼真图像生成算法，另一方则开发出识别它们的方法。
- **公众意识和教育**：公众意识推广和教育活动将是推动AI编辑图像负责任使用以及打击虚假信息传播的重要手段。
- **保护艺术家形象权利**：像OpenAI、Google、StabilityAI这样的公司在训练大型文本到图像模型时，因从互联网抓取艺术家作品而未予以任何形式的署名，面临大量诉讼。图像中毒（image poisoning）是一项新兴的研究问题，其中艺术家的图像在上传到互联网上之前被添加了人眼不可见的噪点像素变化。这有可能破坏训练数据，从而削弱模型的图像生成能力，尤其是在直接抓取的情况下。您可以在[这里](https://www.technologyreview.com/2023/10/23/1082189/data-poisoning-artists-fight-generative-ai/)和[这里](https://arxiv.org/abs/2310.13828)了解更多相关信息。

这是一个快速发展的领域，保持对最新进展的了解至关重要。

## 结论

本节总结了我们关于生成视觉模型的单元，您学习了生成对抗网络（GAN）、变分自编码器（VAE）和扩散模型（Diffusion Models）。
您了解了它们的实现和使用方法，并在本章中探讨了有关这些模型的伦理和偏见的重要议题。

随着本单元的结束，您也完成了本课程最基础的部分，包括_基础知识_、_卷积神经网络_、_视觉Transformer_和_生成模型_。
在接下来的章节中，我们将深入探讨如_视频及视频处理_、_3D视觉、场景渲染和重建_以及_模型优化_等专业领域。
但首先，我们将了解基础的计算机视觉任务——它们的用途、定义以及如何评估。